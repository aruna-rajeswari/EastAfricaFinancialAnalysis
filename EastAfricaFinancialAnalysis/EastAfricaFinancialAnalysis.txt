import numpy as np
import pandas as pd
from pathlib import Path


# -------------------------
# Extract Data
# -------------------------
def extract_data(path="C:/Aruna/Fortrary/DA Workshop/4-Assignment Project/financial_inclusion_dataset.csv"):
    return pd.read_csv(path)


# -------------------------
# Clean Data
# -------------------------
def clean_data(df):
    df = df.copy()  # avoid SettingWithCopyWarning

    # -------------------------
    # AGE CLEANING
    # -------------------------
    df.loc[(df['age'] < 15) | (df['age'] > 100), 'age'] = np.nan
    df['age'] = df['age'].fillna(df.groupby('country')['age'].transform('median'))
    df['age'] = df['age'].fillna(df['age'].median())
    df['age'] = df['age'].round(0).astype(int)

    # -------------------------
    # has_bank_account CLEANING
    # -------------------------
    df['has_bank_account'] = df['has_bank_account'].astype(str).str.lower().str.strip()
    mapping = {'yes': 1, '1': 1, 'true': 1,
               'no': 0, '0': 0, 'false': 0}
    df['has_bank_account'] = df['has_bank_account'].map(mapping)
    df['has_bank_account'] = df['has_bank_account'].fillna(np.nan)

    # -------------------------
    # MONTHLY INCOME CLEANING
    # -------------------------
    df['monthly_income'] = pd.to_numeric(df['monthly_income'], errors='coerce')
    df.loc[df['monthly_income'] < 0, 'monthly_income'] = np.nan
    df['monthly_income'] = df['monthly_income'].fillna(
        df.groupby('country')['monthly_income'].transform('median')
    )
    df['monthly_income'] = df['monthly_income'].fillna(df['monthly_income'].median())
    df['monthly_income'] = df['monthly_income'].round(2)

    # -------------------------
    # OTHER CATEGORICAL COLUMNS
    # -------------------------
    categorical_cols = ['gender', 'education_level', 'mobile_money_user', 'loan_access', 'country']
    for col in categorical_cols:
        df[col] = df[col].replace('', pd.NA).fillna('Unknown')

    # -------------------------
    # REMOVE DUPLICATES
    # -------------------------
    df_temp = df.copy()
    # Temporarily fill NaNs in object columns with placeholder
    for col in df_temp.select_dtypes(include='object').columns:
        df_temp[col] = df_temp[col].fillna('___NaN___')
    # Drop duplicates
    df_temp = df_temp.drop_duplicates()
    # Restore NaNs in object columns
    for col in df_temp.select_dtypes(include='object').columns:
        df_temp[col] = df_temp[col].replace('___NaN___', np.nan)
    df = df_temp

    return df


# -------------------------
# Validate Data
# -------------------------
def validate_data(df):
    print("===== Dataset Validation Summary =====\n")
    
    # Total rows and columns
    print(f"Total rows: {df.shape[0]}")
    print(f"Total columns: {df.shape[1]}\n")
    
    # Duplicate rows
    num_duplicates = df.duplicated().sum()
    print(f"Duplicate rows: {num_duplicates}\n")
    
    # Null values (NaN)
    print("Null values per column:")
    print(df.isnull().sum())
    print("\n")
    
    # Missing / blank values (empty strings or strings with only spaces)
    print("Missing / blank values per column:")
    missing_counts = {}
    for col in df.columns:
        if df[col].dtype == object:
            missing_counts[col] = df[col].str.strip().eq('').sum()
        else:
            missing_counts[col] = 0
    print(pd.Series(missing_counts))
    print("\n")
    
    print("===== Validation Complete =====")


# -------------------------
# Save Cleaned Data
# -------------------------
def save_data(df, filename="C:/Aruna/Fortrary/DA Workshop/4-Assignment Project/Cleaned_financial_inclusion_dataset.csv"):
    Path(filename).parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(filename, index=False, na_rep='NaN')
    return filename


# -------------------------
# MAIN
# -------------------------
if __name__ == "__main__":
    # Extract raw data
    df = extract_data("C:/Aruna/Fortrary/DA Workshop/4-Assignment Project/financial_inclusion_dataset.csv")
    
    # Clean data (removes duplicates, cleans columns)
    df_clean = clean_data(df)
    
    # Validate cleaned dataset
    validate_data(df_clean)
    
    # Save cleaned dataset
    save_data(df_clean, "C:/Aruna/Fortrary/DA Workshop/4-Assignment Project/Cleaned_financial_inclusion_dataset.csv")
    print("Saved Cleaned_financial_inclusion_dataset.csv **********")
